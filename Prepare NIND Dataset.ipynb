{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pairs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"datasets/NIND\"):\n",
    "#     print(root, len(files))\n",
    "    \n",
    "    if len(files) > 0:\n",
    "#         print(files)\n",
    "        \n",
    "        label = [f for f in files if \"ISO80.\" in f]\n",
    "#         print(\"label:\", label)\n",
    "        \n",
    "        if len(label) == 0:\n",
    "            label = [f for f in files if \"ISO100.\" in f]\n",
    "        if len(label) == 0:\n",
    "            label = [f for f in files if \"ISO200.\" in f]\n",
    "            \n",
    "        assert len(label) == 1\n",
    "        \n",
    "        others = list(set(files) - set(label))\n",
    "#         print(\"others:\", others)\n",
    "        \n",
    "        for f in others:\n",
    "            image_pairs.append((os.path.join(root, f), os.path.join(root, label[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('datasets/NIND\\\\BruegelLibraryS1\\\\NIND_BruegelLibraryS1_ISO2500.png',\n",
       " 'datasets/NIND\\\\BruegelLibraryS1\\\\NIND_BruegelLibraryS1_ISO200.png')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_pairs[np.random.randint(0, len(image_pairs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pairs = pd.DataFrame(\n",
    "    image_pairs,\n",
    "    columns=[\"input_image\", \"label_image\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_image</th>\n",
       "      <th>label_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIND_banana_ISO2000.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIND_banana_ISO800.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIND_banana_ISO4000.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIND_banana_ISOH3.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NIND_banana_ISO500.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               input_image             label_image\n",
       "0  NIND_banana_ISO2000.png  NIND_banana_ISO200.png\n",
       "1   NIND_banana_ISO800.png  NIND_banana_ISO200.png\n",
       "2  NIND_banana_ISO4000.png  NIND_banana_ISO200.png\n",
       "3    NIND_banana_ISOH3.png  NIND_banana_ISO200.png\n",
       "4   NIND_banana_ISO500.png  NIND_banana_ISO200.png"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pairs[\"input_image\"] = df_image_pairs.input_image.apply(lambda s:os.path.basename(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pairs[\"label_image\"] = df_image_pairs.label_image.apply(lambda s:os.path.basename(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_image</th>\n",
       "      <th>label_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIND_banana_ISO2000.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIND_banana_ISO800.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIND_banana_ISO4000.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIND_banana_ISOH3.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NIND_banana_ISO500.png</td>\n",
       "      <td>NIND_banana_ISO200.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               input_image             label_image\n",
       "0  NIND_banana_ISO2000.png  NIND_banana_ISO200.png\n",
       "1   NIND_banana_ISO800.png  NIND_banana_ISO200.png\n",
       "2  NIND_banana_ISO4000.png  NIND_banana_ISO200.png\n",
       "3    NIND_banana_ISOH3.png  NIND_banana_ISO200.png\n",
       "4   NIND_banana_ISO500.png  NIND_banana_ISO200.png"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pairs.to_csv(\"NIND-noisy_clean_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(\"datasets/NIND/**/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dir = \"datasets/NIND-1_1/\"\n",
    "# os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# for f in files:\n",
    "#     shutil.copyfile(f, os.path.join(target_dir, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_images_train, noisy_images_test, clean_images_train, clean_images_test = train_test_split(df_image_pairs[\"input_image\"], df_image_pairs[\"label_image\"], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(noisy_images_train), len(noisy_images_test), len(clean_images_train), len(clean_images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_image_to_size(img, target_width, target_height, resize=False):\n",
    "    \"\"\"\n",
    "    Fit an image to a target width and height, with the option of whether or not to\n",
    "    resize the source image to the target width and height while maintaining its aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        img: The image to be fitted to the target width and height in np.ndarray format.\n",
    "        target_width: The target width of the resized image.\n",
    "        target_height: The target height of the resized image.\n",
    "        resize: Whether to resize image to fit to target width and height.\n",
    "        \n",
    "    Returns:\n",
    "        A new image of target width and height with the source image fitted into it.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(img, np.ndarray), \"Image must be of type np.ndarray.\"\n",
    "    assert len(img.shape) == 3, \"Can only accept 3 dimensional image.\"\n",
    "\n",
    "    assert target_width >= 1, \"Invalid target width: {}\".format(target_width)\n",
    "    assert target_height >= 1, \"Invalid target height: {}\".format(target_height)\n",
    "    \n",
    "    if img.shape[2] == 4:\n",
    "        img = skimage.color.rgba2rgb(img, background=(255, 255, 255))\n",
    "        \n",
    "    assert img.shape[2] == 3, \"Number of channels in image must be 3, got: {}\".format(img.shape[2])\n",
    "\n",
    "    canvas = np.zeros(\n",
    "        shape=(int(target_height), int(target_width), img.shape[2]), \n",
    "        dtype=np.float32\n",
    "    )\n",
    "#     print(\"canvas.shape:\", canvas.shape)\n",
    "\n",
    "#     print(\"img.shape:\", img.shape)\n",
    "#     print(\"img:\", img)\n",
    "\n",
    "    if resize:\n",
    "        src_img_width = img.shape[1]\n",
    "        src_img_height = img.shape[0]\n",
    "\n",
    "        width_ratio = target_width / src_img_width\n",
    "        height_ratio = target_height / src_img_height\n",
    "#         print(\"width_ratio:\", width_ratio)\n",
    "#         print(\"height_ratio:\", height_ratio)\n",
    "        ratio = min(width_ratio, height_ratio)\n",
    "\n",
    "        img_resized = skimage.transform.resize(\n",
    "            img, (int(ratio * src_img_height), int(ratio * src_img_width))\n",
    "        )\n",
    "#         print(\"img_resized.shape:\", img_resized.shape)\n",
    "    else:\n",
    "        if np.issubdtype(img.dtype, np.unsignedinteger):\n",
    "            img_resized = img / np.float32(255)\n",
    "        else:\n",
    "            img_resized = img\n",
    "\n",
    "    img_resized = img_resized.astype(np.float32)\n",
    "\n",
    "    # Paste (resized or original) image on canvas\n",
    "    size_dim_0 = min(img_resized.shape[0], canvas.shape[0])\n",
    "    size_dim_1 = min(img_resized.shape[1], canvas.shape[1])\n",
    "    size_dim_2 = min(img_resized.shape[2], canvas.shape[2])\n",
    "    \n",
    "    canvas[\n",
    "        : size_dim_0,\n",
    "        : size_dim_1,\n",
    "        : size_dim_2\n",
    "    ] = img_resized[\n",
    "        : size_dim_0,\n",
    "        : size_dim_1,\n",
    "        : size_dim_2\n",
    "    ]\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_image_pair(img1_paths, img2_paths, img1_base_dir, img2_base_dir, scale=1/2.):\n",
    "def resize_image_pair(p1, p2, img1_base_dir, img2_base_dir, scale=1/2.):   \n",
    "#     for p1, p2, in zip(img1_paths, img2_paths):\n",
    "#         if os.path.isfile(os.path.join(img1_base_dir, os.path.basename(p1))) and os.path.isfile(os.path.join(img2_base_dir, os.path.basename(p2))):\n",
    "#             continue\n",
    "#             return\n",
    "        \n",
    "        img1 = skimage.io.imread(p1)\n",
    "        img2 = skimage.io.imread(p2)\n",
    "        \n",
    "#         img1_resized = fit_image_to_size(img1, target_width=target_width, target_height=target_height, resize=resize)\n",
    "#         img2_resized = fit_image_to_size(img2, target_width=target_width, target_height=target_height, resize=resize)\n",
    "\n",
    "        img1_resized = skimage.transform.resize(img1, (int(img1.shape[0] * scale), int(img1.shape[1] * scale)))\n",
    "        img2_resized = skimage.transform.resize(img2, (int(img2.shape[0] * scale), int(img2.shape[1] * scale)))\n",
    "        \n",
    "        os.makedirs(img1_base_dir, exist_ok=True)\n",
    "        os.makedirs(img2_base_dir, exist_ok=True)\n",
    "        \n",
    "        skimage.io.imsave(os.path.join(img1_base_dir, os.path.basename(p1)), img1_resized)\n",
    "        skimage.io.imsave(os.path.join(img2_base_dir, os.path.basename(p2)), img2_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    list(map(lambda p: executor.submit(resize_image_pair, \n",
    "                                       p1=p[0], \n",
    "                                       p2=p[1], \n",
    "                                       img1_base_dir=\"NIND-1_8/test/noisy/\", \n",
    "                                       img2_base_dir=\"NIND-1_8/test/clean/\",\n",
    "                                       scale=0.125), zip(noisy_images_test, clean_images_test)))\n",
    "    \n",
    "# resize_image_pair(img1_paths=noisy_images_train,\n",
    "#                   img2_paths=clean_images_train, \n",
    "#                   img1_base_dir=\"NIND-1_2/train/noisy/\",\n",
    "#                   img2_base_dir=\"NIND-1_2/train/clean/\",\n",
    "# #                   target_width=1920, target_height=1080,\n",
    "# #                   resize=True\n",
    "#                   scale=0.5\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFRecord files from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_image_pair_example2(input_image_path, label_image_path):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "\n",
    "    input_image = np.array(Image.open(input_image_path))\n",
    "    label_image = np.array(Image.open(label_image_path))\n",
    "\n",
    "    with open(input_image_path, \"rb\") as f:\n",
    "        input_image_str = f.read()\n",
    "    with open(label_image_path, \"rb\") as f:\n",
    "        label_image_str = f.read()\n",
    "\n",
    "    feature = {\n",
    "        \"input_image/filename\": _bytes_feature(\n",
    "            tf.compat.as_bytes(os.path.basename(input_image_path))\n",
    "        ),\n",
    "        \"input_image/width\": _int64_feature(input_image.shape[1]),\n",
    "        \"input_image/height\": _int64_feature(input_image.shape[0]),\n",
    "        \"input_image/channels\": _int64_feature(3),\n",
    "        \"input_image/raw\": _bytes_feature(input_image_str),\n",
    "        \n",
    "        \"label_image/filename\": _bytes_feature(\n",
    "            tf.compat.as_bytes(os.path.basename(label_image_path))\n",
    "        ),\n",
    "        \"label_image/width\": _int64_feature(label_image.shape[1]),\n",
    "        \"label_image/height\": _int64_feature(label_image.shape[0]),\n",
    "        \"label_image/channels\": _int64_feature(3), # XXX WATCH OUT FOR DEPTH\n",
    "        \"label_image/raw\": _bytes_feature(label_image_str),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_pair_tfrecords(path, input_images, label_images):\n",
    "    with tf.python_io.TFRecordWriter(path) as writer:\n",
    "        count = 0\n",
    "\n",
    "        for input_image_path, label_image_path in zip(input_images, label_images):\n",
    "            example = serialize_image_pair_example2(input_image_path, label_image_path)\n",
    "            writer.write(example)\n",
    "            count += 1\n",
    "\n",
    "            if count % 10 == 0:\n",
    "                print(count)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# create_image_pair_tfrecords(\"train-nind.tfrecords\", noisy_images_train, clean_images_train)\n",
    "\n",
    "create_image_pair_tfrecords(\"train-nind-1_8.tfrecords\", \n",
    "                                  [os.path.join(\"NIND-1_8/train/noisy/\", os.path.basename(f)) for f in noisy_images_train], \n",
    "                                  [os.path.join(\"NIND-1_8/train/clean/\", os.path.basename(f)) for f in clean_images_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# create_image_pair_tfrecords(\"val-nind.tfrecords\", noisy_images_test, clean_images_test)\n",
    "\n",
    "create_image_pair_tfrecords(\"val-nind-1_8.tfrecords\", \n",
    "                                  [os.path.join(\"NIND-1_8/test/noisy/\", os.path.basename(f)) for f in noisy_images_test], \n",
    "                                  [os.path.join(\"NIND-1_8/test/clean/\", os.path.basename(f)) for f in clean_images_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord files validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_pair_example2(example_proto):\n",
    "    # Create a dictionary describing the features.\n",
    "    dataset_feature_description = {\n",
    "        \"input_image/filename\": tf.FixedLenFeature([], tf.string),\n",
    "        \"input_image/width\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"input_image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"input_image/channels\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"input_image/raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \n",
    "        \"label_image/filename\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label_image/width\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"label_image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"label_image/channels\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"label_image/raw\": tf.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    example = tf.parse_single_example(example_proto, dataset_feature_description)\n",
    "\n",
    "    input_image = tf.image.decode_image(example[\"input_image/raw\"], 3, dtype=tf.float32)\n",
    "    label_image = tf.image.decode_image(example[\"label_image/raw\"], 3, dtype=tf.float32) # XXX WATCH OUT FOR DEPTH\n",
    "    \n",
    "    return input_image, label_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 15, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that our input pipeline works\n",
    "\n",
    "dataset = tf.data.TFRecordDataset([\"datasets/val-nind-1_8.tfrecords\"])\n",
    "dataset = dataset.map(parse_image_pair_example2).shuffle(20).batch(1)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "input_images_tensor, label_images_tensor = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    test_input_images, test_label_images = sess.run(\n",
    "        [input_images_tensor, label_images_tensor]\n",
    "    )\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(test_input_images[0])\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(np.squeeze(test_label_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
